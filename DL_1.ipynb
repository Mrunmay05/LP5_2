{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koklGpBIPhb8"
   },
   "outputs": [],
   "source": [
    "# Linear regression by using Deep Neural network: Implement Boston housing price\n",
    "# prediction problem by Linear regression using Deep Neural network. Use Boston House\n",
    "# price prediction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQyPdKUTPmBk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bmHi58b_Qb1Y",
    "outputId": "da3c8433-834a-464e-fd05-bfcdf6fe4ecb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"BostonHousing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "619BZgKsQcBU",
    "outputId": "8d583909-53da-4d62-de26-248c7301b015"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crim       0\n",
       "zn         0\n",
       "indus      0\n",
       "chas       0\n",
       "nox        0\n",
       "rm         0\n",
       "age        0\n",
       "dis        0\n",
       "rad        0\n",
       "tax        0\n",
       "ptratio    0\n",
       "b          0\n",
       "lstat      0\n",
       "medv       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Si5mFOwAQ2xn",
    "outputId": "615c67a9-8967-4840-87ad-3f6b9333f696"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crim       float64\n",
       "zn         float64\n",
       "indus      float64\n",
       "chas         int64\n",
       "nox        float64\n",
       "rm         float64\n",
       "age        float64\n",
       "dis        float64\n",
       "rad          int64\n",
       "tax          int64\n",
       "ptratio    float64\n",
       "b          float64\n",
       "lstat      float64\n",
       "medv       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "heDvX1WrQ9C-",
    "outputId": "654e7d3b-27eb-42ef-9ec5-b74712aab035"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FK1xxGmtQ9c8",
    "outputId": "d2c39a8a-8bbf-4155-dc3f-cfc606a676de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7084"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RGstatzQ9qn",
    "outputId": "96c6bbf7-b67f-4d2b-cc4f-1c97370c45f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.loc[:,df.columns!='medv']\n",
    "y = df.loc[:,df.columns=='medv']\n",
    "print(x.shape)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "gTzaapcITUFL"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "x_train =mms.fit_transform(x_train)\n",
    "x_test =mms.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Sr_sSJnPlqY"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37ukiXUlUZJp",
    "outputId": "70da7719-be99-4a4f-b46a-f27fc88f9fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 128)               1792      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_output (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,113\n",
      "Trainable params: 10,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128,input_shape = (13,),activation = 'relu',name='dense_1'))\n",
    "model.add(Dense(64,activation = 'relu',name = 'dense_2'))\n",
    "model.add(Dense(1,activation='linear',name='dense_output'))\n",
    "\n",
    "model.compile(optimizer = 'adam',loss='mse',metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7NDDMjtUb0l",
    "outputId": "57c2f52b-dc1f-4cc1-b4de-1bf27bea6acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 570.0920 - mae: 22.1166 - val_loss: 526.0779 - val_mae: 20.9611\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 526.6133 - mae: 21.0596 - val_loss: 483.0474 - val_mae: 19.8330\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 474.4443 - mae: 19.7281 - val_loss: 421.3080 - val_mae: 18.0682\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 397.8361 - mae: 17.5585 - val_loss: 334.8241 - val_mae: 15.1886\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 295.9071 - mae: 14.3743 - val_loss: 237.6989 - val_mae: 11.2610\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 195.6400 - mae: 11.0217 - val_loss: 168.5381 - val_mae: 10.4363\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 135.1680 - mae: 8.8907 - val_loss: 152.7623 - val_mae: 10.4119\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 120.4100 - mae: 8.4632 - val_loss: 141.1578 - val_mae: 9.8885\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 107.0866 - mae: 7.8978 - val_loss: 118.3632 - val_mae: 9.0415\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 94.3221 - mae: 7.1733 - val_loss: 102.3086 - val_mae: 8.3720\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 83.6580 - mae: 6.7112 - val_loss: 90.8092 - val_mae: 7.9296\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 74.5406 - mae: 6.2778 - val_loss: 78.5659 - val_mae: 7.3532\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 67.6969 - mae: 5.8875 - val_loss: 67.9642 - val_mae: 6.8424\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 62.1442 - mae: 5.5646 - val_loss: 58.4654 - val_mae: 6.3188\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 57.3400 - mae: 5.3239 - val_loss: 52.7421 - val_mae: 5.9860\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 54.6640 - mae: 5.1857 - val_loss: 46.6199 - val_mae: 5.5429\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 51.9942 - mae: 4.9532 - val_loss: 42.3705 - val_mae: 5.2176\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 50.2251 - mae: 4.8357 - val_loss: 39.7177 - val_mae: 5.0489\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 48.6314 - mae: 4.7908 - val_loss: 37.0071 - val_mae: 4.8398\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 47.0699 - mae: 4.6673 - val_loss: 35.2828 - val_mae: 4.7077\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 45.7596 - mae: 4.6038 - val_loss: 33.6724 - val_mae: 4.6005\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 44.5174 - mae: 4.5428 - val_loss: 32.2788 - val_mae: 4.5083\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 43.1779 - mae: 4.4641 - val_loss: 30.9949 - val_mae: 4.4011\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 42.1082 - mae: 4.3602 - val_loss: 29.8862 - val_mae: 4.3302\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 40.7521 - mae: 4.3758 - val_loss: 28.7725 - val_mae: 4.2661\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 39.7623 - mae: 4.2297 - val_loss: 26.9852 - val_mae: 4.0282\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2548 - mae: 4.1660 - val_loss: 26.6512 - val_mae: 4.1264\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 37.3885 - mae: 4.2340 - val_loss: 25.6844 - val_mae: 4.0438\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.1236 - mae: 4.0244 - val_loss: 23.9400 - val_mae: 3.7839\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 34.9377 - mae: 3.9519 - val_loss: 23.8307 - val_mae: 3.8568\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 34.0216 - mae: 3.9904 - val_loss: 22.8723 - val_mae: 3.7695\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.2503 - mae: 3.7897 - val_loss: 21.0797 - val_mae: 3.5277\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.9012 - mae: 3.8144 - val_loss: 20.7018 - val_mae: 3.5716\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.4310 - mae: 3.8577 - val_loss: 19.2569 - val_mae: 3.3366\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.8187 - mae: 3.6143 - val_loss: 19.0460 - val_mae: 3.3055\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.0048 - mae: 3.7588 - val_loss: 19.4408 - val_mae: 3.4044\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 29.2296 - mae: 3.5872 - val_loss: 17.0586 - val_mae: 3.0798\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 28.2900 - mae: 3.5152 - val_loss: 17.3586 - val_mae: 3.1068\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 28.0343 - mae: 3.6512 - val_loss: 17.4680 - val_mae: 3.1103\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.0582 - mae: 3.4488 - val_loss: 15.6439 - val_mae: 2.8673\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.6638 - mae: 3.4228 - val_loss: 15.9444 - val_mae: 2.9080\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.1462 - mae: 3.4688 - val_loss: 14.6834 - val_mae: 2.7549\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.6733 - mae: 3.3889 - val_loss: 14.8903 - val_mae: 2.7784\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.3738 - mae: 3.3369 - val_loss: 14.4971 - val_mae: 2.7184\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 24.9196 - mae: 3.3407 - val_loss: 14.2920 - val_mae: 2.7181\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 24.8798 - mae: 3.3013 - val_loss: 13.3879 - val_mae: 2.6089\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 24.3696 - mae: 3.3269 - val_loss: 14.0545 - val_mae: 2.6832\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.9936 - mae: 3.2605 - val_loss: 13.4981 - val_mae: 2.5750\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 24.0055 - mae: 3.2222 - val_loss: 12.7344 - val_mae: 2.5228\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 23.8445 - mae: 3.3244 - val_loss: 13.2823 - val_mae: 2.6206\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 23.2306 - mae: 3.1758 - val_loss: 12.2433 - val_mae: 2.4730\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.0494 - mae: 3.1847 - val_loss: 12.5650 - val_mae: 2.5884\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.1410 - mae: 3.1650 - val_loss: 11.4370 - val_mae: 2.4477\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.7898 - mae: 3.1858 - val_loss: 12.3145 - val_mae: 2.5844\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.5547 - mae: 3.1582 - val_loss: 12.4013 - val_mae: 2.5873\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.4990 - mae: 3.2045 - val_loss: 11.7048 - val_mae: 2.4878\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.3659 - mae: 3.1013 - val_loss: 11.2611 - val_mae: 2.4698\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.2301 - mae: 3.2304 - val_loss: 12.8707 - val_mae: 2.6825\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.0211 - mae: 3.1123 - val_loss: 11.2610 - val_mae: 2.4313\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.0339 - mae: 3.0630 - val_loss: 12.0194 - val_mae: 2.6214\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.8171 - mae: 3.1962 - val_loss: 10.4770 - val_mae: 2.4293\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.4926 - mae: 3.0508 - val_loss: 10.2103 - val_mae: 2.3554\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.7093 - mae: 3.0445 - val_loss: 10.7872 - val_mae: 2.4875\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.3199 - mae: 3.1190 - val_loss: 10.8988 - val_mae: 2.4855\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.1668 - mae: 3.0471 - val_loss: 10.2423 - val_mae: 2.3634\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.1336 - mae: 3.0657 - val_loss: 10.5866 - val_mae: 2.4536\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.9222 - mae: 3.0360 - val_loss: 10.1870 - val_mae: 2.3918\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.9172 - mae: 3.0209 - val_loss: 10.3828 - val_mae: 2.4252\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.8946 - mae: 3.0786 - val_loss: 10.1159 - val_mae: 2.3706\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.7194 - mae: 2.9923 - val_loss: 10.1401 - val_mae: 2.3710\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 20.6817 - mae: 3.0702 - val_loss: 9.8592 - val_mae: 2.3703\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 20.5161 - mae: 2.9712 - val_loss: 9.9171 - val_mae: 2.3547\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.4281 - mae: 3.0120 - val_loss: 10.0983 - val_mae: 2.3609\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.3007 - mae: 2.9785 - val_loss: 10.3382 - val_mae: 2.4264\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.1325 - mae: 2.9877 - val_loss: 9.2679 - val_mae: 2.2863\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.1729 - mae: 2.9678 - val_loss: 9.0554 - val_mae: 2.2930\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.8556 - mae: 2.9807 - val_loss: 9.8514 - val_mae: 2.3833\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.8789 - mae: 2.9846 - val_loss: 9.2519 - val_mae: 2.2671\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.7989 - mae: 2.9792 - val_loss: 8.9983 - val_mae: 2.2820\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.5159 - mae: 2.9361 - val_loss: 8.9769 - val_mae: 2.2687\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.5148 - mae: 2.9217 - val_loss: 9.6836 - val_mae: 2.3593\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.2983 - mae: 2.9167 - val_loss: 8.5190 - val_mae: 2.1928\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.3886 - mae: 2.8849 - val_loss: 8.8808 - val_mae: 2.2852\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.3081 - mae: 2.9648 - val_loss: 8.8631 - val_mae: 2.2526\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.1705 - mae: 2.8831 - val_loss: 8.9088 - val_mae: 2.2668\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.0183 - mae: 2.9090 - val_loss: 8.7550 - val_mae: 2.2288\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.8267 - mae: 2.9241 - val_loss: 9.4451 - val_mae: 2.3231\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.8370 - mae: 2.8923 - val_loss: 8.9887 - val_mae: 2.2621\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.7299 - mae: 2.8966 - val_loss: 8.9583 - val_mae: 2.2725\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.6395 - mae: 2.9121 - val_loss: 9.3092 - val_mae: 2.3007\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.7725 - mae: 2.8687 - val_loss: 8.8840 - val_mae: 2.2635\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.6283 - mae: 2.9325 - val_loss: 7.8756 - val_mae: 2.1246\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.3442 - mae: 2.8211 - val_loss: 7.9978 - val_mae: 2.1395\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.3144 - mae: 2.8848 - val_loss: 8.0207 - val_mae: 2.1408\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.2931 - mae: 2.8269 - val_loss: 7.5260 - val_mae: 2.0659\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.0313 - mae: 2.8693 - val_loss: 9.1967 - val_mae: 2.3031\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.0524 - mae: 2.8308 - val_loss: 8.0809 - val_mae: 2.1377\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17.9314 - mae: 2.8157 - val_loss: 8.0255 - val_mae: 2.1632\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17.7634 - mae: 2.7965 - val_loss: 7.3427 - val_mae: 2.0364\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17.6260 - mae: 2.7825 - val_loss: 7.8766 - val_mae: 2.1284\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=100,validation_split=0.05,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0EF-RljUcLy",
    "outputId": "664e476e-c471-4c38-e148-2f1d9c74e1e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 768us/step - loss: 11.2535 - mae: 2.5636\n",
      "MSE :  11.253540992736816\n",
      "MAE :  2.5635838508605957\n"
     ]
    }
   ],
   "source": [
    "mse,mae = model.evaluate(x_test,y_test) #returns mse, mae\n",
    "print('MSE : ',mse)\n",
    "print('MAE : ',mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDe6pjeWVX9A",
    "outputId": "ea5adf09-ce79-493f-83b0-4030e6b8ddbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 580us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30.700693 ],\n",
       "       [26.969242 ],\n",
       "       [17.61709  ],\n",
       "       [21.758646 ],\n",
       "       [21.015545 ],\n",
       "       [21.39378  ],\n",
       "       [30.440998 ],\n",
       "       [18.508335 ],\n",
       "       [21.79785  ],\n",
       "       [25.483532 ],\n",
       "       [29.611742 ],\n",
       "       [29.561356 ],\n",
       "       [18.33911  ],\n",
       "       [22.209925 ],\n",
       "       [21.224884 ],\n",
       "       [19.898893 ],\n",
       "       [15.008244 ],\n",
       "       [43.7746   ],\n",
       "       [27.154673 ],\n",
       "       [11.690361 ],\n",
       "       [19.449785 ],\n",
       "       [14.183339 ],\n",
       "       [24.745274 ],\n",
       "       [25.504734 ],\n",
       "       [29.518888 ],\n",
       "       [10.580434 ],\n",
       "       [13.121114 ],\n",
       "       [19.494326 ],\n",
       "       [39.602043 ],\n",
       "       [14.86991  ],\n",
       "       [23.770273 ],\n",
       "       [15.718684 ],\n",
       "       [44.860237 ],\n",
       "       [17.878572 ],\n",
       "       [21.252993 ],\n",
       "       [18.783653 ],\n",
       "       [16.846249 ],\n",
       "       [29.728584 ],\n",
       "       [11.57606  ],\n",
       "       [19.831532 ],\n",
       "       [24.324791 ],\n",
       "       [23.257288 ],\n",
       "       [29.137165 ],\n",
       "       [14.93811  ],\n",
       "       [17.796331 ],\n",
       "       [12.460041 ],\n",
       "       [45.636513 ],\n",
       "       [17.350668 ],\n",
       "       [22.412117 ],\n",
       "       [15.005007 ],\n",
       "       [25.952986 ],\n",
       "       [22.425097 ],\n",
       "       [26.151127 ],\n",
       "       [24.066042 ],\n",
       "       [11.6148   ],\n",
       "       [24.594702 ],\n",
       "       [12.249274 ],\n",
       "       [26.704182 ],\n",
       "       [17.727533 ],\n",
       "       [40.84694  ],\n",
       "       [18.616774 ],\n",
       "       [27.416574 ],\n",
       "       [15.942021 ],\n",
       "       [15.255275 ],\n",
       "       [11.666819 ],\n",
       "       [33.721107 ],\n",
       "       [42.86207  ],\n",
       "       [23.350752 ],\n",
       "       [23.290514 ],\n",
       "       [23.721647 ],\n",
       "       [24.629519 ],\n",
       "       [10.756947 ],\n",
       "       [16.675848 ],\n",
       "       [20.916243 ],\n",
       "       [18.972841 ],\n",
       "       [22.353773 ],\n",
       "       [40.03139  ],\n",
       "       [26.522028 ],\n",
       "       [29.056177 ],\n",
       "       [34.157753 ],\n",
       "       [19.834959 ],\n",
       "       [22.550945 ],\n",
       "       [35.54715  ],\n",
       "       [12.738374 ],\n",
       "       [23.367634 ],\n",
       "       [28.44636  ],\n",
       "       [16.098207 ],\n",
       "       [26.203207 ],\n",
       "       [17.855663 ],\n",
       "       [18.599056 ],\n",
       "       [28.964077 ],\n",
       "       [48.49176  ],\n",
       "       [17.110514 ],\n",
       "       [21.143385 ],\n",
       "       [11.894614 ],\n",
       "       [20.328638 ],\n",
       "       [22.915575 ],\n",
       "       [26.988535 ],\n",
       "       [41.9326   ],\n",
       "       [19.675297 ],\n",
       "       [13.416973 ],\n",
       "       [17.111666 ],\n",
       "       [25.896479 ],\n",
       "       [23.133905 ],\n",
       "       [11.655675 ],\n",
       "       [20.927649 ],\n",
       "       [12.822494 ],\n",
       "       [32.502384 ],\n",
       "       [21.080547 ],\n",
       "       [25.703793 ],\n",
       "       [43.133293 ],\n",
       "       [27.637054 ],\n",
       "       [12.842038 ],\n",
       "       [35.00956  ],\n",
       "       [38.219    ],\n",
       "       [35.58223  ],\n",
       "       [21.068876 ],\n",
       "       [15.288277 ],\n",
       "       [35.06848  ],\n",
       "       [43.523853 ],\n",
       "       [20.300758 ],\n",
       "       [13.972957 ],\n",
       "       [29.808155 ],\n",
       "       [19.34249  ],\n",
       "       [25.343412 ],\n",
       "       [19.375204 ],\n",
       "       [25.516392 ],\n",
       "       [21.78232  ],\n",
       "       [18.76108  ],\n",
       "       [28.617487 ],\n",
       "       [19.105818 ],\n",
       "       [22.928947 ],\n",
       "       [27.860538 ],\n",
       "       [12.695991 ],\n",
       "       [25.957    ],\n",
       "       [32.1817   ],\n",
       "       [14.49477  ],\n",
       "       [12.903729 ],\n",
       "       [35.479702 ],\n",
       "       [12.5043335],\n",
       "       [21.032412 ],\n",
       "       [17.73755  ],\n",
       "       [16.402952 ],\n",
       "       [27.81397  ],\n",
       "       [32.898514 ],\n",
       "       [21.624567 ],\n",
       "       [24.706678 ],\n",
       "       [16.023577 ],\n",
       "       [27.448673 ],\n",
       "       [19.59524  ],\n",
       "       [35.507904 ],\n",
       "       [15.557484 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = model.predict(x_test)\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFEVTtcrV1fK",
    "outputId": "6a95200c-5305-485f-82bd-1a49b47e39d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.700693,\n",
       " 26.969242,\n",
       " 17.61709,\n",
       " 21.758646,\n",
       " 21.015545,\n",
       " 21.39378,\n",
       " 30.440998,\n",
       " 18.508335,\n",
       " 21.79785,\n",
       " 25.483532,\n",
       " 29.611742,\n",
       " 29.561356,\n",
       " 18.33911,\n",
       " 22.209925,\n",
       " 21.224884,\n",
       " 19.898893,\n",
       " 15.008244,\n",
       " 43.7746,\n",
       " 27.154673,\n",
       " 11.690361,\n",
       " 19.449785,\n",
       " 14.183339,\n",
       " 24.745274,\n",
       " 25.504734,\n",
       " 29.518888,\n",
       " 10.580434,\n",
       " 13.121114,\n",
       " 19.494326,\n",
       " 39.602043,\n",
       " 14.86991,\n",
       " 23.770273,\n",
       " 15.718684,\n",
       " 44.860237,\n",
       " 17.878572,\n",
       " 21.252993,\n",
       " 18.783653,\n",
       " 16.846249,\n",
       " 29.728584,\n",
       " 11.57606,\n",
       " 19.831532,\n",
       " 24.324791,\n",
       " 23.257288,\n",
       " 29.137165,\n",
       " 14.93811,\n",
       " 17.796331,\n",
       " 12.460041,\n",
       " 45.636513,\n",
       " 17.350668,\n",
       " 22.412117,\n",
       " 15.005007,\n",
       " 25.952986,\n",
       " 22.425097,\n",
       " 26.151127,\n",
       " 24.066042,\n",
       " 11.6148,\n",
       " 24.594702,\n",
       " 12.249274,\n",
       " 26.704182,\n",
       " 17.727533,\n",
       " 40.84694,\n",
       " 18.616774,\n",
       " 27.416574,\n",
       " 15.942021,\n",
       " 15.255275,\n",
       " 11.666819,\n",
       " 33.721107,\n",
       " 42.86207,\n",
       " 23.350752,\n",
       " 23.290514,\n",
       " 23.721647,\n",
       " 24.629519,\n",
       " 10.756947,\n",
       " 16.675848,\n",
       " 20.916243,\n",
       " 18.972841,\n",
       " 22.353773,\n",
       " 40.03139,\n",
       " 26.522028,\n",
       " 29.056177,\n",
       " 34.157753,\n",
       " 19.834959,\n",
       " 22.550945,\n",
       " 35.54715,\n",
       " 12.738374,\n",
       " 23.367634,\n",
       " 28.44636,\n",
       " 16.098207,\n",
       " 26.203207,\n",
       " 17.855663,\n",
       " 18.599056,\n",
       " 28.964077,\n",
       " 48.49176,\n",
       " 17.110514,\n",
       " 21.143385,\n",
       " 11.894614,\n",
       " 20.328638,\n",
       " 22.915575,\n",
       " 26.988535,\n",
       " 41.9326,\n",
       " 19.675297,\n",
       " 13.416973,\n",
       " 17.111666,\n",
       " 25.896479,\n",
       " 23.133905,\n",
       " 11.655675,\n",
       " 20.927649,\n",
       " 12.822494,\n",
       " 32.502384,\n",
       " 21.080547,\n",
       " 25.703793,\n",
       " 43.133293,\n",
       " 27.637054,\n",
       " 12.842038,\n",
       " 35.00956,\n",
       " 38.219,\n",
       " 35.58223,\n",
       " 21.068876,\n",
       " 15.288277,\n",
       " 35.06848,\n",
       " 43.523853,\n",
       " 20.300758,\n",
       " 13.972957,\n",
       " 29.808155,\n",
       " 19.34249,\n",
       " 25.343412,\n",
       " 19.375204,\n",
       " 25.516392,\n",
       " 21.78232,\n",
       " 18.76108,\n",
       " 28.617487,\n",
       " 19.105818,\n",
       " 22.928947,\n",
       " 27.860538,\n",
       " 12.695991,\n",
       " 25.957,\n",
       " 32.1817,\n",
       " 14.49477,\n",
       " 12.903729,\n",
       " 35.479702,\n",
       " 12.5043335,\n",
       " 21.032412,\n",
       " 17.73755,\n",
       " 16.402952,\n",
       " 27.81397,\n",
       " 32.898514,\n",
       " 21.624567,\n",
       " 24.706678,\n",
       " 16.023577,\n",
       " 27.448673,\n",
       " 19.59524,\n",
       " 35.507904,\n",
       " 15.557484]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps=[]\n",
    "\n",
    "for i in y1:\n",
    "    ps.append(list(i)[0])\n",
    "\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "MNCcrJ-eXJuq"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame({'actual':y_test['medv'],'predicted':ps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Q84ZirXzXMmc",
    "outputId": "5bb8f710-b660-4c0f-f26b-e71aa14a8f95"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>28.2</td>\n",
       "      <td>30.700693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>23.9</td>\n",
       "      <td>26.969242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>16.6</td>\n",
       "      <td>17.617090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>22.0</td>\n",
       "      <td>21.758646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>20.8</td>\n",
       "      <td>21.015545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>19.1</td>\n",
       "      <td>16.023577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>28.4</td>\n",
       "      <td>27.448673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>20.5</td>\n",
       "      <td>19.595240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>33.8</td>\n",
       "      <td>35.507904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.5</td>\n",
       "      <td>15.557484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted\n",
       "307    28.2  30.700693\n",
       "343    23.9  26.969242\n",
       "47     16.6  17.617090\n",
       "67     22.0  21.758646\n",
       "362    20.8  21.015545\n",
       "..      ...        ...\n",
       "467    19.1  16.023577\n",
       "95     28.4  27.448673\n",
       "122    20.5  19.595240\n",
       "260    33.8  35.507904\n",
       "23     14.5  15.557484\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ch0HLZIsXNeX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
